# Rename all files in the files list, and rename them by renaming the part before the first "_" with the integer in order
# Also, save the part that we renamed as well as the integers we assigned them to in a csv file, so that it's easy to see which file corresponds to which participant
for(i in 1:length(files)) {
# Print "Renaming [worker_id] to [num]"
print(paste0("Renaming ", files[i], " to ", i))
file.rename(files[i], paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i]))))
files[i] <- paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i])))
}
# Also anonymize the 'workerID' field in each file to the integer we assigned it to, and save the file
for(i in 1:length(files)) {
myJSON <- fromJSON(files[i])
# We should save the myJSON$workerID as the integer before the first "_"
w_num <- substr(files[i], 1, regexpr("_", files[i])-1)
print(paste0(files[i], " -- ", w_num))
myJSON$workerID <- w_num
# Change workerId's in the trialStructs as well
myJSON$trialStruct['workerId'] <- rep(w_num, dim(myJSON$trialStruct['workerId'])[1])
# Write the text into files[i]
write(toJSON(myJSON), files[i])
}
worker_ids <- c()
nums <- c()
for(i in 1:length(filenames_old)) {
worker_ids <- c(worker_ids, substr(filenames_old[i], 1, regexpr("_", filenames_old[i]) - 1))
nums <- c(nums, substr(files[i], 1, regexpr("_", files[i]) - 1))
}
filenames <- as.data.frame(cbind(worker_ids, nums))
colnames(filenames) <- c('worker_id', 'integer')
# Remove NA column
filenames <- filenames[filenames$worker_id != 'NA',]
filenames$`NA`<- NULL
write.csv(filenames, 'filenames_e1.csv')
}
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment S1
## clear workspace
rm(list = ls())
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(lsr)) {install.packages("lsr"); require(lsr)}
if (!require(lsmeans)) {install.packages("lsmean"); require(lsmeans)}
if (!require(nnet)) {install.packages("nnet"); require(nnet)}
if (!require(mlogit)) {install.packages("mlogit"); require(mlogit)}
library(ggrepel)
##================ import data ================================================================================================
## set directory to data folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
setwd("../data/")
datalist = list()
#import data using jsonlite [automate this, by defining list of data frames]
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
##================ anonymize worker ids ========================================
if(TRUE) {
filenames_old <- list.files(pattern=('*txt'))
# Rename all files in the files list, and rename them by renaming the part before the first "_" with the integer in order
# Also, save the part that we renamed as well as the integers we assigned them to in a csv file, so that it's easy to see which file corresponds to which participant
for(i in 1:length(files)) {
# Print "Renaming [worker_id] to [num]"
print(paste0("Renaming ", files[i], " to ", i))
file.rename(files[i], paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i]))))
files[i] <- paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i])))
}
# Also anonymize the 'workerID' field in each file to the integer we assigned it to, and save the file
for(i in 1:length(files)) {
myJSON <- fromJSON(files[i])
# We should save the myJSON$workerID as the integer before the first "_"
w_num <- substr(files[i], 1, regexpr("_", files[i])-1)
print(paste0(files[i], " -- ", w_num))
myJSON$workerID <- w_num
# Change workerId's in the trialStructs as well
#myJSON$trialStruct['workerId'] <- rep(w_num, dim(myJSON$trialStruct['workerId'])[1])
# Write the text into files[i]
write(toJSON(myJSON), files[i])
}
worker_ids <- c()
nums <- c()
for(i in 1:length(filenames_old)) {
worker_ids <- c(worker_ids, substr(filenames_old[i], 1, regexpr("_", filenames_old[i]) - 1))
nums <- c(nums, substr(files[i], 1, regexpr("_", files[i]) - 1))
}
filenames <- as.data.frame(cbind(worker_ids, nums))
colnames(filenames) <- c('worker_id', 'integer')
# Remove NA column
filenames <- filenames[filenames$worker_id != 'NA',]
filenames$`NA`<- NULL
write.csv(filenames, 'filenames_e1.csv')
}
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The capacity of personal identity
#Experiment 5
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
## set directory to data folder
dir <- setwd("/Users/julian/Dropbox (Personal)/Research/Intuition/single_identity/pilots/e8_memory_association_self/data")
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The capacity of personal identity
#Experiment 5
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(devtools)) {install.packages("devtools"); require(devtools)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
##================================================================================================================
##IMPORT DATA##
##================================================================================================================
## set directory to data folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
setwd("../data/")
datalist = list()
#import data using jsonlite [automate this, by defining list of data frames]
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
length(unique(data$workerId)) #1 subjects
#check that we have equal numbers for each condition
table(data$label)
table(data$cond)
if(TRUE) {
filenames_old <- list.files(pattern=('*txt'))
# Rename all files in the files list, and rename them by renaming the part before the first "_" with the integer in order
# Also, save the part that we renamed as well as the integers we assigned them to in a csv file, so that it's easy to see which file corresponds to which participant
for(i in 1:length(files)) {
# Print "Renaming [worker_id] to [num]"
print(paste0("Renaming ", files[i], " to ", i))
file.rename(files[i], paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i]))))
files[i] <- paste0(i, substr(files[i], regexpr("_", files[i]), nchar(files[i])))
}
# Also anonymize the 'workerID' field in each file to the integer we assigned it to, and save the file
for(i in 1:length(files)) {
myJSON <- fromJSON(files[i])
# We should save the myJSON$workerID as the integer before the first "_"
w_num <- substr(files[i], 1, regexpr("_", files[i])-1)
print(paste0(files[i], " -- ", w_num))
myJSON$workerID <- w_num
# Change workerId's in the trialStructs as well
myJSON$trialStruct['workerId'] <- rep(w_num, dim(myJSON$trialStruct['workerId'])[1])
# Write the text into files[i]
write(toJSON(myJSON), files[i])
}
worker_ids <- c()
nums <- c()
for(i in 1:length(filenames_old)) {
worker_ids <- c(worker_ids, substr(filenames_old[i], 1, regexpr("_", filenames_old[i]) - 1))
nums <- c(nums, substr(files[i], 1, regexpr("_", files[i]) - 1))
}
filenames <- as.data.frame(cbind(worker_ids, nums))
colnames(filenames) <- c('worker_id', 'integer')
# Remove NA column
filenames <- filenames[filenames$worker_id != 'NA',]
filenames$`NA`<- NULL
write.csv(filenames, 'filenames_e1.csv')
}
R.home()
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 2
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(pwr)) {install.packages("pwr"); require(pwr)}
if (!require(BayesFactor)) {install.packages("BayesFactor"); require(BayesFactor)}
d <- 1.06 # Anticipated effect size
pwr.t.test(d=d, power=0.9)
pwr.t.test(n=100, d=1.06)
?pwr.t.test
pwr.t.test(n=100, sig.level=0.05, power=0.8)
pwr.t.test(sig.level=0.05, power=0.8, d=0.28)
pwr.t.test(sig.level=0.05, power=0.8, d=0.28, type="one.sample")
pwr.t.test(sig.level=0.05, power=0.8, d=0.28, type="two.sample")
pwr.t.test(sig.level=0.05, power=0.8, d=0.28, alternative="less")
pwr.t.test(sig.level=0.05, power=0.8, d=0.28, alternative="greater")
pwr.t.test(sig.level=0.05, power=0.8, d=0.28, alternative="two.sided")
?v
?parameterEstimates
pwr.t2n.test(n1 = 31, n2 = 31, d = NULL, sig.level = 0.05, power = 0.80)
?pwr.t2n.test
pwr.t.test(d=d, power=0.9)
#Julian De Freitas, 2019
#Analysis script for De Freitas, Rips, & Alvarez - The limit of personal identity
#Experiment 2
## clear workspace
rm(list = ls())
options(download.file.method="libcurl")
## necessary libraries
if (!require(rjson)) {install.packages("rjson"); require(rjson)}
if (!require(ggplot2)) {install.packages("ggplot2"); require(ggplot2)}
if (!require(ltm)) {install.packages("ltm"); require(ltm)}
if (!require(heplots)) {install.packages("heplots"); require(heplots)}
if (!require(lmtest)) {install.packages("lmtest"); require(lmtest)}
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}
if (!require(jsonlite)) {install.packages("jsonlite"); require(jsonlite)}
if (!require(plyr)) {install.packages("plyr"); require(plyr)}
if (!require(lme4)) {install.packages("lme4"); require(lme4)}
if (!require(reshape2)) {install.packages("reshape2"); require(reshape2)}
if (!require(RColorBrewer)) {install.packages("RColorBrewer"); require(RColorBrewer)}
if (!require(Hmisc)) {install.packages("Hmisc"); require(Hmisc)}
if (!require(ggpubr)) {install.packages("ggpubr"); require(ggpubr)}
if (!require(ggsignif)) {install.packages("ggsignif"); require(ggsignif)}
if (!require(gridExtra)) {install.packages("gridExtra"); require(gridExtra)}
if (!require(pwr)) {install.packages("pwr"); require(pwr)}
if (!require(BayesFactor)) {install.packages("BayesFactor"); require(BayesFactor)}
## set directory to data folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
setwd("../data/")
datalist = list()
#import data using jsonlite [automate this, by defining list of data frames]
files <- list.files(pattern=('*txt'))
for (i in 1:length(files)) {
curData <- fromJSON(files[i], simplifyDataFrame = TRUE)
datalist[[i]] <- curData$trialStruct
}
data = do.call(rbind, datalist)
head(data)
dim(data)
#check that we have equal numbers for each condition
table(data$image)
table(data$label)
table(data$agentCond)
table(data$matchCond)
table(data$condNum)
table(data$condNum)[1]/300
table(data$condNum)[2]/300
table(data$condNum)[3]/300
#number of workers before exclusions
n_bef_excl <- length(unique(data$workerId)); n_bef_excl
##================================================================================================================
##EXCLUSIONS##
##================================================================================================================
#perform exclusions: attention, comprehension, and rts < 200 (this ends up performing both subject and trial)
#note, we exclude based on mean accuracy further below
data <- subset(data,(data$attentionMCQ=="0" & data$comp =="D"))
length(unique(data$workerId)) #1 subjects
data$rt[is.na(data$rt)] <- 0
#mark which trials had reasonable rts
for(i in 1:dim(data)[1]) {
if(data$rt[i] >= 100) {
data$badRt[i] = 0
}
else {
data$badRt[i] = 1
}
}
#exclude subjects with lower than 55% average accuracy
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0 #if na, just say it's accuracy of 0
perf_thresh <- 0.6
trial_thresh <- 0.4
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
exc <- 0
#if their accuracy < 55% or total bad RTs > 50% of trials, exclude them from dataset
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
if( (ss_excl_mat[i,1] < perf_thresh) & (ss_excl_mat[i,2] > trial_thresh) ) {
exc <- exc + 1
data <- subset(data,data$workerId != workers[i])
}
}
print(paste0("Exclusions from main performance: ", exc))
#check it worked
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
ss_excl_mat <- array(0,dim=c(length(workers),2))
colnames(ss_excl_mat) <- c('mean_acc', 'rt_err_prop')
for(i in 1:length(workers)) {
ss_excl_mat[i,1] <- c(mean(acc_use[worker==workers[i]])) #get accuracy for each worker
ss_excl_mat[i,2] <- sum(data$badRt[data$workerId == workers[i]])/length(data$rt[data$workerId == workers[i]])
}
#final subjects after exclusions
length(unique(data$workerId)) #24 subjects
#check that numbers for each condition look reasonable
table(data$image)
table(data$label)
table(data$agentCond)
table(data$matchCond)
table(data$condNum)
#assign variable names
worker <- as.factor(data$workerId)
workers <- as.factor(unique(worker))
n_aft_excl <- length(workers); n_aft_excl
n_excl <- n_bef_excl - n_aft_excl; n_excl
age <- as.numeric(data$age); mean(age,na.rm = TRUE)
gender <- as.factor(data$sex); table(gender)[1]/sum(table(gender))
##================================================================================================================
##DATA PREP##
##================================================================================================================
acc <- as.numeric(data$acc)
acc_use <- acc
acc_use[is.na(acc_use)] <- 0
numTrials <- dim(data)[1]
matchCond <- as.factor(data$matchCond)
agentCond <- as.factor(data$agentCond)
condNum <- as.factor(data$condNum)
#create numeric version of condition
for(i in 1:length(agentCond)) {
if(condNum[i] == 1) {
if(agentCond[i] == 'young-you') {
data$agentCond_n[i] = 1
}
else if(agentCond[i] == 'stranger-john') {
data$agentCond_n[i] = 2
}
else if(agentCond[i] == 'stranger-bill') {
data$agentCond_n[i] = 3
}
}
else if(condNum[i] == 2) {
if(agentCond[i] == 'young-you') {
data$agentCond_n[i] = 1
}
else if(agentCond[i] == 'old-you') {
data$agentCond_n[i] = 2
}
else if(agentCond[i] == 'stranger-john') {
data$agentCond_n[i] = 3
}
data$condNum[i] <- 3
#condNum[i] <- 3
}
else if(condNum[i] == 3) {
if(agentCond[i] == 'old-you') {
data$agentCond_n[i] = 1
}
else if(agentCond[i] == 'stranger-john') {
data$agentCond_n[i] = 2
}
else if(agentCond[i] == 'stranger-bill') {
data$agentCond_n[i] = 3
}
data$condNum[i] <- 2
#condNum[i] <- 2
}
}
condNum <- as.factor(data$condNum)
agentCond_n <- as.factor(data$agentCond_n)
ans <- as.factor(data$ans)
corrAns <- as.factor(data$corrAns)
rts <- log(as.numeric(data$rt))
agentConds_n <- as.factor(unique(agentCond_n))
matchConds <- unique(matchCond)
label <- as.factor(data$label)
#create matrix for collecting d prime-relevant values, and rts
d_mat <- array(0,dim=c(3*length(workers),7))
colnames(d_mat) <- c('worker', 'mainCond', 'agentCond', 'hits', 'false_alarms', 'd', 'rt')
d.mat <- as.data.frame(d_mat, stringsAsFactors=FALSE); d.mat
#for each worker and agent condition, get average hits, false alarms, d-prime, and rt
#hits: proportion of true hits you said were hits (out of all true hits)
#false alarms: proportin of non hits you said were hits (out of all non hits)
#get rts for trials that were correct
counter <- 1
for(i in 1:length(workers)) {
for(j in 1:length(agentConds_n)) {
length_h <- length(acc_use[worker==workers[i] & agentCond_n==j & corrAns=='y'])
length_fa <- length(acc_use[worker==workers[i] & agentCond_n==j & corrAns=='n'])
h <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='y'])/length_h
fa <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n'])/length_fa
rt <- mean(rts[worker==workers[i] & agentCond_n==j & acc_use==1], na.rm=TRUE)
#see https://stats.stackexchange.com/questions/134779/d-prime-with-100-hit-rate-probability-and-0-false-alarm-probability
if(h==1) { h <- (length_h - 0.5) / length_h }
if(h==0) { h <- 0.5 / length_h }
if(fa==1) { fa <- (length_fa - 0.5) / length_fa }
if(fa==0) { fa <- 0.5 / length_fa }
d.mat[counter,] <- c(workers[i],unique(condNum[worker==workers[i]]), j, h, fa, qnorm(h) - qnorm(fa), rt)
counter = counter + 1
}
}
# collect total performance and performance difference (cond 1 - 2) for each subject
perf_mat <- array(0, dim=c(length(workers), 3))
colnames(perf_mat) <- c('mainCond', 'perf_diff', 'total_perf')
perf.mat <- as.data.frame(perf_mat, stringsAsFactors=FALSE); perf.mat
for(i in 1:length(workers)) {
print(i)
print(workers[i])
perf.mat[i,1] <- unique(d.mat$mainCond[d.mat$worker==i])
if(unique(d.mat$mainCond[d.mat$worker==i]) %in% c(1, 2)) {
#future-you1 - john
perf.mat[i,2] <- d.mat$d[d.mat$worker==i & d.mat$agentCond == 1] - d.mat$d[d.mat$worker==i & d.mat$agentCond == 2]
} else if(unique(d.mat$mainCond[d.mat$worker==i]) == 3) {
#best of future-you1 and future-you2 - john
perf.mat[i,2] <- max(d.mat$d[d.mat$worker==i & d.mat$agentCond == 1], d.mat$d[d.mat$worker==i & d.mat$agentCond == 2]) - d.mat$d[d.mat$worker==i & d.mat$agentCond == 3]
}
perf.mat[i,3] <- d.mat$d[d.mat$worker==i & d.mat$agentCond == 1] + d.mat$d[d.mat$worker==i & d.mat$agentCond == 2] + d.mat$d[d.mat$worker==i & d.mat$agentCond == 3]
}
#make matrix for measuring confusions
conf_mat <- array(0,dim=c(3*length(workers),7))
colnames(conf_mat) <- c('worker', 'self_cond', 'agentCond', 'n_fa', 'n_self', 'n_stranger', 'diff')
conf.mat <- as.data.frame(conf_mat, stringsAsFactors=FALSE); conf.mat
counter <- 1
for(i in 1:length(workers)) {
for(j in 1:length(agentConds_n)) {
total_fa <- length(acc_use[worker==workers[i] & agentCond_n==j & corrAns=='n'])
length_fa <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n'])/total_fa
length_self <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n' & (label == 'young-you' | label == 'old-you')])/total_fa
length_stranger <- length(acc_use[worker==workers[i] & agentCond_n==j & ans=='y' & corrAns=='n' & label == 'stranger-john'])/total_fa
conf.mat[counter,] <- c (workers[i], unique(condNum[worker==workers[i]]),
j, length_fa, length_self, length_stranger, length_self - length_stranger )
counter = counter + 1
}
}
conf.mat <- subset(conf.mat, conf.mat$self_cond == 3)
#------- GROUP MEANS--------#
p_mat <- rep(9, times = 5)
star_mat <- rep(9, times = 5)
#one self
d_one <- subset(d.mat, d.mat$mainCond==1)
mean(d_one$d[d_one$agentCond==1]) #future-you1
sd(d_one$d[d_one$agentCond==1])
n_o_1 = length(d_one$d[d_one$agentCond==1]); n_o_1
mean(d_one$d[d_one$agentCond==2]) #stranger-john
sd(d_one$d[d_one$agentCond==2])
n_o_2 = length(d_one$d[d_one$agentCond==2])
dim(d_one$d[d_one$agentCond==1])
length(d_one$d[d_one$agentCond==1])
length(d_one$d[d_one$agentCond==2])
length(d_one$d[d_one$agentCond==3])
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]))
length(d_one$d[d_one$agentCond==1])
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]), power = 0.8, sig.level = 0.05)
d_oneAlt <- subset(d.mat, d.mat$mainCond==2)
length(d_oneAlt$d[d_oneAlt$agentCond==1])
pwr.t.test(n=length(d_oneAlt$d[d_oneAlt$agentCond==1]), power = 0.8, sig.level = 0.05)
d <- 1.06 # Anticipated effect size
pwr.t.test(d=d, power=0.9)
pwr.t.test(d=d, power=0.9, paired = TRUE)
?pwr.t.test
pwr.t.test(d=d, power=0.9, type = "paired")
pwr.t.test(n=length(d_oneAlt$d[d_oneAlt$agentCond==1]), power = 0.8, sig.level = 0.05)
pwr.t.test(n=length(d_oneAlt$d[d_oneAlt$agentCond==1]), power = 0.8, sig.level = 0.05, type="paired")
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]), power = 0.8, sig.level = 0.05)
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]), power = 0.8, sig.level = 0.05, type="paired")
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]), power = 0.9, sig.level = 0.05, type="paired")
pwr.t.test(n=length(d_one$d[d_one$agentCond==1]), power = 0.8, sig.level = 0.05, type="paired")
pwr.t.test(n=length(d_oneAlt$d[d_oneAlt$agentCond==1]), power = 0.8, sig.level = 0.05, type="paired")
length(d_two$d[d_two$agentCond==1])
d_two <- subset(d.mat, d.mat$mainCond==3)
length(d_two$d[d_two$agentCond==1])
pwr.t.test(n=length(d_two$d[d_two$agentCond==1]), power = 0.8, sig.level = 0.05, type="paired")
